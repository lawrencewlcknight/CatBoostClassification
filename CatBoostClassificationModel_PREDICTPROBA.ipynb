{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d50a4f",
   "metadata": {},
   "source": [
    "# CatBoost Classification Model - Predict Probability of Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6caa063",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Benefits-of-Catboost-Algorithm\" data-toc-modified-id=\"Benefits-of-Catboost-Algorithm-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Benefits of Catboost Algorithm</a></span></li><li><span><a href=\"#Import-Packages\" data-toc-modified-id=\"Import-Packages-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import Packages</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Read-in-Data\" data-toc-modified-id=\"Read-in-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Read in Data</a></span></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>EDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Univariate,-Bivariate,-Correlation-Analysis\" data-toc-modified-id=\"Univariate,-Bivariate,-Correlation-Analysis-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Univariate, Bivariate, Correlation Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlation-Matrix\" data-toc-modified-id=\"Correlation-Matrix-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Correlation Matrix</a></span></li><li><span><a href=\"#Univariate-Analysis\" data-toc-modified-id=\"Univariate-Analysis-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Univariate Analysis</a></span></li><li><span><a href=\"#Bivariate-Analysis\" data-toc-modified-id=\"Bivariate-Analysis-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>Bivariate Analysis</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extreme-Values\" data-toc-modified-id=\"Extreme-Values-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Extreme Values</a></span></li><li><span><a href=\"#Missing-Values\" data-toc-modified-id=\"Missing-Values-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Missing Values</a></span></li><li><span><a href=\"#Set-Features-to-Categorical\" data-toc-modified-id=\"Set-Features-to-Categorical-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Set Features to Categorical</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Train,-Validate,-Test-Split\" data-toc-modified-id=\"Train,-Validate,-Test-Split-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Train, Validate, Test Split</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Model Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Selection---Round-1\" data-toc-modified-id=\"Feature-Selection---Round-1-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Feature Selection - Round 1</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li><li><span><a href=\"#Feature-Selection---Round-2\" data-toc-modified-id=\"Feature-Selection---Round-2-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Feature Selection - Round 2</a></span></li><li><span><a href=\"#Find-Optimal-Number-of-Trees\" data-toc-modified-id=\"Find-Optimal-Number-of-Trees-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Find Optimal Number of Trees</a></span></li></ul></li><li><span><a href=\"#Fit-Final-Model\" data-toc-modified-id=\"Fit-Final-Model-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Fit Final Model</a></span></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Table-of-Metrics\" data-toc-modified-id=\"Table-of-Metrics-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>Table of Metrics</a></span></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Confusion Matrix</a></span></li><li><span><a href=\"#ROC-Curve\" data-toc-modified-id=\"ROC-Curve-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;</span>ROC Curve</a></span></li><li><span><a href=\"#Lift-Chart\" data-toc-modified-id=\"Lift-Chart-13.4\"><span class=\"toc-item-num\">13.4&nbsp;&nbsp;</span>Lift Chart</a></span></li><li><span><a href=\"#Feature-Importance\" data-toc-modified-id=\"Feature-Importance-13.5\"><span class=\"toc-item-num\">13.5&nbsp;&nbsp;</span>Feature Importance</a></span></li><li><span><a href=\"#Feature-Summary-Plots\" data-toc-modified-id=\"Feature-Summary-Plots-13.6\"><span class=\"toc-item-num\">13.6&nbsp;&nbsp;</span>Feature Summary Plots</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56837d-65ee-4213-8887-131721320494",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* The problem was to train a classification model on a structured dataset\n",
    "* ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbe82b",
   "metadata": {},
   "source": [
    "## Benefits of Catboost Algorithm\n",
    "\n",
    "* High performance without parameter tuning.\n",
    "* Native handling of categorical features - no need for one hot encoding.\n",
    "* Ordered boosting to overcome overfitting.\n",
    "* Insenstive to outliers.\n",
    "* Scale invariant to input features - no need for normalisation/standardisation\n",
    "* Non-parameteric - no distributional assumptions made.\n",
    "* Insentitive to correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325e2f2",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from scipy.stats import pearsonr\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffc50b-fd83-434c-ac7e-2bf7feeba464",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c34cd-80ae-4964-a8dd-cdb4cc6d4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"<>\"\n",
    "\n",
    "OOT_DATE = \"<>\"\n",
    "\n",
    "VAL_SET_PROP = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TARGET = \"label\"\n",
    "OBJECTIVE = \"Logloss\"\n",
    "METRIC = \"Logloss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edab7e",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(DATA_PATH, sheet_name=\"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104faa8-71e4-4b0a-9a7a-4ddb207e3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2128f78",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6816f2",
   "metadata": {},
   "source": [
    "EDA Performed\n",
    "\n",
    "* Checked for missing values.\n",
    "* Features were reviewed for erroneous values e.g. negative ages.\n",
    "* Data was inspected for highly correlated values - none where found.\n",
    "* Features with zero variance searched for and removed.\n",
    "* Univariate and Bivariate analysis was carried out.\n",
    "* Checked for duplicate rows - none were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns are in the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missing values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d4040-0eb8-4b6b-9338-f8c8a851c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1494efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9e494-da99-442e-b5ae-ba16fffcf62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c934f-3681-48a0-9794-2297c90ddbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "\n",
    "df.drop(columns=['<>']).duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be7e4b",
   "metadata": {},
   "source": [
    "### Univariate, Bivariate, Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd87396",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1e972",
   "metadata": {},
   "source": [
    "Catboost preformance isn't affected by including highly correlated features. If this were a logistic regression model we'd need to remove two of these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb883db",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_high_cardinality = list(df.loc[:, df.nunique() > 10])\n",
    "cols_low_cardinality = list(df.loc[:, df.nunique() <= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2540a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in cols_low_cardinality:\n",
    "    ax = df[feature].value_counts().plot(kind='bar',\n",
    "                                    figsize=(6,4),\n",
    "                                    title= \"Count by level: \" + str(feature))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_high_cardinality.remove(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580911b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in cols_high_cardinality:\n",
    "    ax = df[feature].hist(bins=10)\n",
    "    plt.title(\"Histogram: \" + str(feature))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46998b6",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e066b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_low_cardinality.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f22236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in cols_low_cardinality:\n",
    "    ax = df[[feature, 'label']].groupby(by=[feature], dropna=True).mean().plot(kind='bar',\n",
    "                                                                               figsize=(8,4),\n",
    "                                                                               title= \"Mean label by level: \" + str(feature)\n",
    "                                                                              )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62e3c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in cols_high_cardinality:\n",
    "    df[feature + \"_Banded\"] = pd.cut(df[feature], bins=10)\n",
    "    \n",
    "    ax = df[[feature + \"_Banded\", 'label']].groupby(by=[feature + \"_Banded\"], dropna=True).mean().plot(kind='bar',\n",
    "                                                                               figsize=(8,4),\n",
    "                                                                               title= \"Mean label by level: \" + str(feature)\n",
    "                                                                              )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a2af8",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9964815-72ba-4c51-b91d-9e069ca6baa6",
   "metadata": {},
   "source": [
    "* Features with zero variance were removed.\n",
    "* Erroneous values - e.g. negative ages - were \"corrected\" where found.\n",
    "* Missing values were set to -99 - a value outside the range of natural values for all features amended.\n",
    "* Payment_type, sales_channel1, underwriting, and vitality11 were classified as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b03c8",
   "metadata": {},
   "source": [
    "### Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a7a81-1202-4340-bc15-c909fa701053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with zero variance\n",
    "\n",
    "df = df.drop(columns = ['<>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51344ab-0575-4ed3-b579-b0d85ee625de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for extreme values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f22dd3",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd86daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['<>'] = df['<>'].fillna(-99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae9219",
   "metadata": {},
   "source": [
    "### Set Features to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['<>'] = df['<>'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efc86c-0e0a-4d36-aa0d-12a59b10733c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5fc1a-40b0-4f1a-8799-d28d0d4df64c",
   "metadata": {},
   "source": [
    "* Included a cyclical month columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of predictors to be used in model\n",
    "\n",
    "PREDICTORS = [\n",
    "\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9d993-9723-4c18-bebe-54d92b56dd07",
   "metadata": {},
   "source": [
    "## Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547441a5",
   "metadata": {},
   "source": [
    "Need to think about how we ensure there is no target leakage due to customers occuring in multiple datasets.\n",
    "\n",
    "For the predict class model I experimented with a range of the SMOTE oversampling techniques.  In the end using Catboost class weights produced the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17618b-cecb-49dd-b27e-e8c931711fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[df['date'] <= OOT_DATE]\n",
    "df_test = df[df['date'] > OOT_DATE]\n",
    "df_train, df_valid = train_test_split(df_model, \n",
    "                                      test_size = VAL_SET_PROP,\n",
    "                                      stratify=df_model['label'],\n",
    "                                      random_state = RANDOM_SEED)\n",
    "\n",
    "print('Number of rows in df_model: {}'.format(len(df_model)))\n",
    "print('Number of rows in df_train: {}'.format(len(df_train)))\n",
    "print('Number of rows in df_valid: {}'.format(len(df_valid)))\n",
    "print('Number of rows in df_test: {}'.format(len(df_test)))\n",
    "print('Proportion of all data in df_test: {}'.format(len(df_test)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12212a66-5616-46f1-8c3a-66d29b345892",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a29682-001e-414a-9f4c-19e779309ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categoricals(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    \n",
    "    This function returns a list of categorical\n",
    "    features from a given dataframe.\n",
    "    \n",
    "    :param df: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    objs = list(df.select_dtypes(object).columns)\n",
    "    cats = list(df.select_dtypes(\"category\").columns)\n",
    "    return objs + cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986896c-c5ea-4dc1-80e7-071acd43b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pools(features: list,\n",
    "                 target: str,\n",
    "                 df_train: pd.DataFrame,\n",
    "                 df_valid: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function creates the train and validation \n",
    "    pools to pass into the Catboost model.\n",
    "    \n",
    "    :param features: list of features\n",
    "    :param target: target variable\n",
    "    :param df_train: training dataset\n",
    "    :param df_valid: validation dataset\n",
    "    :return: train pool, valid pool\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_pool = Pool(data=df_train[features].values,\n",
    "                      label=df_train[target],\n",
    "                      feature_names=features,\n",
    "                      cat_features=get_categoricals(df_train[features]))\n",
    "    \n",
    "    valid_pool = Pool(data=df_valid[features].values,\n",
    "                      label=df_valid[target],\n",
    "                      feature_names=features,\n",
    "                      cat_features=get_categoricals(df_valid[features]))\n",
    "    \n",
    "    return train_pool, valid_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f227926-d5de-4e55-b5d2-d8f4ca4fe055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(features: list,\n",
    "                      target: str,\n",
    "                      df_train: pd.DataFrame,\n",
    "                      df_valid: pd.DataFrame,\n",
    "                      params: dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to determine the optimum selection of features. \n",
    "    It iteratively fits models each time removing the least important \n",
    "    feature and tracking the minimum loss score acheived.\n",
    "    \n",
    "    Parameters:\n",
    "    :param features: list of features\n",
    "    :param target: target variable\n",
    "    :param df_train: training dataset\n",
    "    :param df_valid: validation dataset\n",
    "    :param params: dictionary of hyperparameters to pass to Catboost\n",
    "    \n",
    "    Returns:\n",
    "    results: tuple of the iteration, model score, and number of features\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    i = 1\n",
    "    selected_features_test = features.copy()\n",
    "    \n",
    "    while len(selected_features_test) > 5:\n",
    "        \n",
    "        train_pool, valid_pool = create_pools(selected_features_test,\n",
    "                                              target,\n",
    "                                              df_train,\n",
    "                                              df_valid)\n",
    "        \n",
    "        model = CatBoostClassifier(**params)\n",
    "        \n",
    "        model.fit(train_pool,\n",
    "                  eval_set=valid_pool,\n",
    "                  early_stopping_rounds=15,\n",
    "                  plot=False,\n",
    "                  verbose=False)\n",
    "        \n",
    "        result = (i, \n",
    "                  len(selected_features_test), \n",
    "                  model.get_best_score()['validation'][params['objective']],\n",
    "                  selected_features_test)\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        feature_importance = model.get_feature_importance(train_pool)\n",
    "        feature_names = selected_features_test.copy()\n",
    "        \n",
    "        selected_features_test = []\n",
    "        for score, name in sorted(zip(feature_importance, feature_names), reverse=True):\n",
    "            if score > 0:\n",
    "                selected_features_test.append(name)\n",
    "                \n",
    "        selected_features_test = selected_features_test[0:len(selected_features_test)-1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d9a2a-62e8-4a31-a08b-331870bcada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tune(features: list,\n",
    "               target: str,\n",
    "               df: pd.DataFrame,\n",
    "               params: dict,\n",
    "               grid: dict):\n",
    "    \"\"\"\n",
    "    This function performs grid search on a set of hyperparamters and\n",
    "    returns a dictionary of the optimal hyperparameters\n",
    "    \n",
    "    Parameters:\n",
    "    :param features: list of features\n",
    "    :param target: target variable\n",
    "    :param df: modelling dataset\n",
    "    :param params: dictionary of fixed hyperparameters to pass to Catboost\n",
    "    :param grid: dictionary of hyperparameters to be tested\n",
    "    :return: grid_search_results\n",
    "    \n",
    "    Returns:\n",
    "    results: tuple of the iteration, model score, and number of features\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    grid_pool = Pool(\n",
    "        data = df[features].values,\n",
    "        label = df[target],\n",
    "        feature_names = features,\n",
    "        cat_features = get_categoricals(df[features]))\n",
    "        \n",
    "    model = CatBoostClassifier(**params)\n",
    "        \n",
    "    grid_search_results = model.grid_search(grid, grid_pool, plot=False)\n",
    "    \n",
    "    return grid_search_results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43d7e3-cae3-4b53-bb12-6207f9a856aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_trees(features: list,\n",
    "                       target: str,\n",
    "                       df_train: pd.DataFrame,\n",
    "                       df_valid: pd.DataFrame,\n",
    "                       params: dict):\n",
    "    \"\"\"\n",
    "    This function finds and returns the optimal number of trees to fit\n",
    "    to a Catboost model.\n",
    "    \n",
    "    Parameters:\n",
    "    :param features: list of features\n",
    "    :param target: target variable\n",
    "    :param df_train: training dataset\n",
    "    :param df_valid: validation dataset\n",
    "    :param params: dictionary of hyperparameters to pass to Catboost\n",
    "    \n",
    "    Returns:\n",
    "    results: the optimal number of trees/iterations\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    train_pool, valid_pool = create_pools(features,\n",
    "                                          target,\n",
    "                                          df_train,\n",
    "                                          df_valid)\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    model.fit(train_pool,\n",
    "              eval_set=valid_pool,\n",
    "              early_stopping_rounds=15,\n",
    "              plot=False,\n",
    "              verbose=False)\n",
    "    \n",
    "    return model.get_best_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a64d4-fb7f-4959-ba99-91da34d86948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_chart(df: pd.DataFrame,\n",
    "               target: str,\n",
    "               predictions: np.array):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe that can be used to plot a lift chart.\n",
    "\n",
    "    Parameters:\n",
    "    :param df: dataset\n",
    "    :param target: target variable\n",
    "    :param predictions: array of model predictions\n",
    "    \n",
    "    Returns:\n",
    "    results: dataframe  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lift_df = df[[target]]\n",
    "    lift_df['Predictions'] = predictions\n",
    "    lift_df.sort_values(by=[\"Predictions\"], inplace=True)\n",
    "    \n",
    "    lift_df[\"Seq\"] = range(1, len(lift_df)+1)\n",
    "    lift_df[\"Bins\"] = pd.qcut(lift_df[\"Seq\"], 100, labels=range(100))\n",
    "    lift_df.drop(columns=[\"Seq\"], inplace=True)\n",
    "    \n",
    "    lift_df = lift_df.groupby(\"Bins\").mean()\n",
    "    \n",
    "    return lift_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394b39e-9e13-4911-943d-59265a612c78",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835b365-2362-4d4b-94ca-c1c68d9ec594",
   "metadata": {},
   "source": [
    "### Feature Selection - Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79902555-3778-4402-be47-967c8cd65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    iterations = 2000,\n",
    "    thread_count = 24,\n",
    "    objective = OBJECTIVE,\n",
    "    random_seed = RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f30280-4e02-4fdd-a191-6cb79542bc5e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_selection(PREDICTORS, TARGET, df_train, df_valid, params)\n",
    "\n",
    "df_results = pd.DataFrame(data = results, columns = ['iteration', 'feature_count', 'score', 'feature_list'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c9659-34b6-49c2-8832-3520d1e54830",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(df_results['feature_count'], df_results['score'], label='loss score')\n",
    "plt.title('First Round Feature Selection')\n",
    "plt.ylabel('loss score')\n",
    "plt.xlabel('number of features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc5df6-3843-4fef-9e08-f3f791c12c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a suboptimal feature set to allow some room for improvement during the hyperparamenter tuning phase.\n",
    "selected_features = df_results.loc[14, \"feature_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e54d8b-5f89-42a6-85fb-97e6de2e725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a71400-1d16-45b1-9120-50fca7b17475",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a331bfa-9c3a-47a3-a59b-49bdbb8403ae",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba46edb-6807-48d4-a65e-d2b8badcbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'learning_rate': [0.01, 0.03, 0.1],\n",
    "    'depth': [3, 4, 5, 6],\n",
    "    'l2_leaf_reg': [2, 3, 4, 5, 6]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6f6ea-1747-40d8-b414-e0dc85777239",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_results = hyper_tune(selected_features, TARGET, df_model, params, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3759731-3bf2-43fc-be29-ced2c7e469f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29de4c-546d-4695-a1e7-1e147bf544e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Selection - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e67e21-bd8c-4251-964f-bc96862cc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    iterations = 2000,\n",
    "    learning_rate = grid_search_results['params']['learning_rate'],\n",
    "    l2_leaf_reg = grid_search_results['params']['l2_leaf_reg'],\n",
    "    thread_count = 24,\n",
    "    depth = grid_search_results['params']['depth'],\n",
    "    objective = OBJECTIVE,\n",
    "    random_seed = RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9941b1b-8c92-4665-9b16-f4410fcd738a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_selection(selected_features, TARGET, df_train, df_valid, params)\n",
    "\n",
    "df_results = pd.DataFrame(data = results, columns = ['iteration', 'feature_count', 'score', 'feature_list'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c68a2-8f21-4a1f-a039-20531bd2318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(df_results['feature_count'], df_results['score'], label='loss score')\n",
    "plt.title('First Round Feature Selection')\n",
    "plt.ylabel('loss score')\n",
    "plt.xlabel('number of features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563ac60-9d72-4992-b379-cacb68ba83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a suboptimal feature set to allow some room for improvement during the hyperparamenter tuning phase.\n",
    "\n",
    "selected_features = df_results.loc[1, \"feature_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489946b7-a590-41cd-92f4-581a9fc56c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bf5f7-15d0-4435-9a7f-ef020b14c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f16ea-88c9-4e6f-8d7d-1e4d6592a334",
   "metadata": {},
   "source": [
    "### Find Optimal Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c382025-eaab-48e7-8304-d26e32e8464a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = find_optimal_trees(selected_features, TARGET, df_train, df_valid, params)\n",
    "\n",
    "iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8487fc-1cae-4756-955c-bb5aee090f28",
   "metadata": {},
   "source": [
    "## Fit Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af867fb9-2347-433d-a717-f5a5b147353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = Pool(data = df_model[selected_features].values,\n",
    "                  label = df_model[TARGET],\n",
    "                  feature_names = selected_features,\n",
    "                  cat_features = get_categoricals(df_model[selected_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d66e1-4a99-4388-9e7e-63c60ebbc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['iterations'] = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261b9a2-a25e-40dc-8506-a97b5b9e5eff",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**params)\n",
    "    \n",
    "model.fit(model_pool, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4506ec-80b2-46e9-96a3-3caa5818d973",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661bb14-d9b2-4a9e-a740-064711ae7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(data = df_test[selected_features].values,\n",
    "                  label = df_test[TARGET],\n",
    "                  feature_names = selected_features,\n",
    "                  cat_features = get_categoricals(df_test[selected_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730fc54-e9bd-4019-b3e3-88cded2a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.eval_metrics(model_pool, [METRIC])[METRIC]\n",
    "test_metrics = model.eval_metrics(test_pool, [METRIC])[METRIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e061c8-34bf-41ec-988b-1010a5af7c8b",
   "metadata": {},
   "source": [
    "### Table of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bbd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = model.predict_proba(model_pool)[:, 1]\n",
    "test_preds = model.predict_proba(test_pool)[:, 1]\n",
    "model_preds_class = model.predict(model_pool)\n",
    "test_preds_class = model.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1eeb4-cf4c-48fb-affb-8878c6a7fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Statistic'] = ['Logloss',\n",
    "                   'Balanced Accuracy Score',\n",
    "                   'f1 score (weighted)',\n",
    "                   'precision',\n",
    "                   'recall',\n",
    "                   'ROC AUC Score',\n",
    "                   'Mean Actual', \n",
    "                   'Mean Prediction', \n",
    "                   'Max Actual', \n",
    "                   'Max Predicted', \n",
    "                   'Min Actual', \n",
    "                   'Min Predicted']\n",
    "\n",
    "df['Model Data'] = [round(model_metrics[-1], 3),\n",
    "                    round(balanced_accuracy_score(df_model[TARGET], model_preds_class), 3),\n",
    "                    round(f1_score(df_model[TARGET], model_preds_class, average='weighted'), 3),\n",
    "                    round(precision_score(df_model[TARGET], model_preds_class), 3),\n",
    "                    round(recall_score(df_model[TARGET], model_preds_class), 3),\n",
    "                    round(roc_auc_score(df_model[TARGET], model_preds_class), 3),\n",
    "                    round(df_model[TARGET].mean(), 3), \n",
    "                    round(model_preds.mean(), 3),\n",
    "                    round(df_model[TARGET].max(), 3), \n",
    "                    round(model_preds.max(), 3), \n",
    "                    round(df_model[TARGET].min(), 3), \n",
    "                    round(model_preds.min(), 3)]\n",
    "\n",
    "df['Test Data'] = [round(test_metrics[-1], 3),\n",
    "                   round(balanced_accuracy_score(df_test[TARGET], test_preds_class), 3),\n",
    "                   round(f1_score(df_test[TARGET], test_preds_class, average='weighted'), 3),\n",
    "                   round(precision_score(df_test[TARGET], test_preds_class), 3),\n",
    "                   round(recall_score(df_test[TARGET], test_preds_class), 3),\n",
    "                   round(roc_auc_score(df_test[TARGET], test_preds_class), 3),\n",
    "                   round(df_test[TARGET].mean(), 3), \n",
    "                   round(test_preds.mean(), 3),\n",
    "                   round(df_test[TARGET].max(), 3), \n",
    "                   round(test_preds.max(), 3), \n",
    "                   round(df_test[TARGET].min(), 3), \n",
    "                   round(test_preds.min(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d093a4",
   "metadata": {},
   "source": [
    "* Balanced Accuracy Score - simple average of class accuracy\n",
    "* F1 score - can be interpreted as a harmonic mean of the precision and recall.\n",
    "* Precision - TP / (TP + FP) - proportion positive class predictions that are correct\n",
    "* Recall - TP / (TP + FN) - proportion of actual positive values identified\n",
    "* ROC AUC Score - Area Under the Receiver Operating Characteristic Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c765e2-6a21-4f1b-815e-b9fbf720b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45308aed",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_options = [\n",
    "    (\"Confusion matrix - Test Set, \", None),\n",
    "    (\"Normalized confusion matrix - Test Set\", \"true\"),\n",
    "]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        df_test[TARGET], \n",
    "        test_preds_class,\n",
    "        normalize=normalize\n",
    "    )\n",
    "    disp.ax_.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef510fa1",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(df_test[TARGET], test_preds_class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c92b6-ac13-4b0e-b288-6a7329bda305",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a17f37-6d65-41d0-941f-2d7c76b85786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "lift_chart(df_model, TARGET, predictions=model_preds).plot(ax=axes[0], title='Modelling Set')\n",
    "lift_chart(df_test, TARGET, predictions=test_preds).plot(ax=axes[1], title='Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3dffe-938e-4929-a794-415393b46d34",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab840f-089c-4eca-9238-25bdbcef15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = model.get_feature_importance(model_pool, type='ShapValues')\n",
    "\n",
    "shap_values = shap_values[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19fa36-0bb8-49ed-bf4d-a0be8921c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = shap.summary_plot(shap_values, df_model[selected_features], plot_type=\"bar\", max_display=20, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d802b-5bb6-4c9c-8ab4-c5da32b873b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6fd0d-512a-47eb-af76-ef832dd6152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature_importance': model.get_feature_importance(model_pool),\n",
    "                                 'feature_names': selected_features}).sort_values(by=['feature_importance'],\n",
    "                                                                                 ascending=False)\n",
    "\n",
    "feature_importance_list = list(feature_importance['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de701cc-3c7d-484a-9d99-b47d278890f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df_model[feature_importance_list].select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e45f0-5822-40ad-a6ff-808439dc032c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for feature in num_cols:\n",
    "    res = model.calc_feature_statistics(model_pool, \n",
    "                                        feature=feature, \n",
    "                                        prediction_type='Probability')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48b385-8565-4421-900c-661fd0c46e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496a9c3-396f-4267-adbb-f7efe352c47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ba2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
